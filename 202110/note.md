# 《机器学习实战》笔记

### 监督学习、非监督学习
- 监督学习：知道预测、目标变量的分类信息。包括分类（离散型目标值）与回归（连续型目标值）。
- 无监督学习：没有类别信息与目标值。包括聚类、密度估计
### 名词解析
- 特征值：每个样本的属性
- 归一化数值：在处理不同取值范围的特征值时，我们通常采用的方法是将数值归一化，如将取值范围处理为0～1、-1～1之间。
- 香农熵：信息的期望值
- 信息增益：在划分数据集之前之后信息发生的变化称为信息增益，获得信息增益最高的特征是最好的选择。
### k-邻近算法（监督学习：分类算法）
- 思想：计算各样本距离、距离递增排序、取k个样本求频率最高的分类。
- 优点：精确度高，对异常值不敏感，无数据输入假定
- 缺点：
1. 必须保存全部数据集，消耗大量存储空间。
2. 必须对数据集中每个数据计算距离值，耗时
3. 无法给出任何数据基本结构信息
- 适用数据范围：数值型、标称型
### 决策树算法（监督学习：分类算法）
- 思想：计算各样本距离、距离递增排序、取k个样本求频率最高的分类。
- 优点：计算复杂度不高，输出结果易于理解，对中间值缺失不敏感，可处理不相关特征数据
- 缺点：
1. 必须保存全部数据集，消耗大量存储空间。
2. 必须对数据集中每个数据计算距离值，耗时
3. 无法给出任何数据基本结构信息
- 适用数据范围：数值型、标称型